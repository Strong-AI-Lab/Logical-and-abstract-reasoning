
metric: "accuracy"
# eval_device: "cpu"
max_length: 400
training_arguments:
  output_dir: "fine-tuning-output"
  per_device_train_batch_size: 64
  per_device_eval_batch_size: 64
  num_train_epochs: 3
  learning_rate: 0.0005
peft:
  peft_type: "LORA"
  task_type: "CAUSAL_LM"
  r: 8
  lora_alpha: 16
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
  lora_dropout: 0.05
  bias: "none"